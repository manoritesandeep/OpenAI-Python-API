{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: StackSample - 10% of Stack Overflow QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get string of the key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11060</td>\n",
       "      <td>912.0</td>\n",
       "      <td>2008-08-14T13:59:21Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>How should I unit test a code-generator?</td>\n",
       "      <td>This is a difficult and open-ended question I ...</td>\n",
       "      <td>11060</td>\n",
       "      <td>I started writing up a summary of my experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17250</td>\n",
       "      <td>394.0</td>\n",
       "      <td>2008-08-20T00:16:40Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>Create an encrypted ZIP file in Python</td>\n",
       "      <td>I'm creating an ZIP file with ZipFile in Pytho...</td>\n",
       "      <td>17250</td>\n",
       "      <td>I created a simple library to create a passwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31340</td>\n",
       "      <td>242853.0</td>\n",
       "      <td>2008-08-27T23:44:47Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>How do threads work in Python, and what are co...</td>\n",
       "      <td>I've been trying to wrap my head around how th...</td>\n",
       "      <td>31340</td>\n",
       "      <td>Yes, because of the Global Interpreter Lock (G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34020</td>\n",
       "      <td>3561.0</td>\n",
       "      <td>2008-08-29T05:43:16Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>Are Python threads buggy?</td>\n",
       "      <td>A reliable coder friend told me that Python's ...</td>\n",
       "      <td>34020</td>\n",
       "      <td>Python threads are good for concurrent I/O pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34570</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2008-08-29T16:10:41Z</td>\n",
       "      <td>2011-11-08T16:11:43Z</td>\n",
       "      <td>13</td>\n",
       "      <td>What is the best quick-read Python book out th...</td>\n",
       "      <td>I am taking a class that requires Python. We w...</td>\n",
       "      <td>34570</td>\n",
       "      <td>I loved Dive Into Python, especially if you're...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0  11060        912.0  2008-08-14T13:59:21Z                   NaN     18   \n",
       "1  17250        394.0  2008-08-20T00:16:40Z                   NaN     24   \n",
       "2  31340     242853.0  2008-08-27T23:44:47Z                   NaN     71   \n",
       "3  34020       3561.0  2008-08-29T05:43:16Z                   NaN     17   \n",
       "4  34570        577.0  2008-08-29T16:10:41Z  2011-11-08T16:11:43Z     13   \n",
       "\n",
       "                                               Title  \\\n",
       "0           How should I unit test a code-generator?   \n",
       "1             Create an encrypted ZIP file in Python   \n",
       "2  How do threads work in Python, and what are co...   \n",
       "3                          Are Python threads buggy?   \n",
       "4  What is the best quick-read Python book out th...   \n",
       "\n",
       "                                                Body  ParentId  \\\n",
       "0  This is a difficult and open-ended question I ...     11060   \n",
       "1  I'm creating an ZIP file with ZipFile in Pytho...     17250   \n",
       "2  I've been trying to wrap my head around how th...     31340   \n",
       "3  A reliable coder friend told me that Python's ...     34020   \n",
       "4  I am taking a class that requires Python. We w...     34570   \n",
       "\n",
       "                                              Answer  \n",
       "0  I started writing up a summary of my experienc...  \n",
       "1  I created a simple library to create a passwor...  \n",
       "2  Yes, because of the Global Interpreter Lock (G...  \n",
       "3  Python threads are good for concurrent I/O pro...  \n",
       "4  I loved Dive Into Python, especially if you're...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_csv(\"python_qa.csv\")\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = qa_df['Body'], qa_df['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       This is a difficult and open-ended question I ...\n",
       "1       I'm creating an ZIP file with ZipFile in Pytho...\n",
       "2       I've been trying to wrap my head around how th...\n",
       "3       A reliable coder friend told me that Python's ...\n",
       "4       I am taking a class that requires Python. We w...\n",
       "                              ...                        \n",
       "4424    I am trying to determine what percentage of th...\n",
       "4425    How can we make a class represent itself as a ...\n",
       "4426    I thought I could make my python (2.7.10) code...\n",
       "4427    Say, I have given a DataFrame with most of the...\n",
       "4428    Let's say I have the following code:\\n\\na = [1...\n",
       "Name: Body, Length: 4429, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I started writing up a summary of my experienc...\n",
       "1       I created a simple library to create a passwor...\n",
       "2       Yes, because of the Global Interpreter Lock (G...\n",
       "3       Python threads are good for concurrent I/O pro...\n",
       "4       I loved Dive Into Python, especially if you're...\n",
       "                              ...                        \n",
       "4424    setup\\ncreate 2 time series\\n\\nfrom StringIO i...\n",
       "4425    TLDR: It's impossible to make custom classes r...\n",
       "4426    You are not indexing. You are yielding a list;...\n",
       "4427    You can create a look up data frame from the d...\n",
       "4428    Use itertools.product within a list comprehens...\n",
       "Name: Answer, Length: 4429, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?\\n',\n",
       " 'completion': \"I loved Dive Into Python, especially if you're a quick study.  The beginning basics are all covered (and may move slowly for you), but the latter few chapters are great learning tools.\\n\\nPlus, Pilgrim is a pretty good writer.\\n\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to JSON\n",
    "# qa_openai_format = [{\"prompt\":\"body\", \"completion\":\"answer\"}]\n",
    "qa_openai_format = [{\"prompt\":q, \"completion\":ans} for q,ans in zip(questions,answers)]\n",
    "qa_openai_format[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_openai_format[4]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model = \"text-babbage-001\",\n",
    "    prompt = qa_openai_format[4]['prompt'],\n",
    "    max_tokens = 250,\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are a few great Python books that you could consider while you are learning Python. One book that is particularly helpful is \"Python for Data Science\" by Geoffrey Hinton. This book is packed with information on data science and Python, and it is a great resource for anyone who wants to learn Python for data science purposes. Another great book to consider is \"Python for Data Science Mastery\" by Michael Nielsen. This book is designed to help you learn more about data science and Python, and it is a great resource for anyone who wants to learn more about Python for data science purposes.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: Model Halucinating... Wrong response as the above stated books by the author does not exist..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model = \"text-davinci-003\",\n",
    "    prompt = qa_openai_format[4]['prompt'],\n",
    "    max_tokens = 250,\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some great Python books to consider include:\n",
      "\n",
      "1. Automate the Boring Stuff with Python by Al Sweigart\n",
      "2. Python Crash Course by Eric Matthes\n",
      "3. Python for Data Analysis by Wes McKinney\n",
      "4. Python Cookbook by David Beazley and Brian K. Jones\n",
      "5. Learning Python by Mark Lutz\n",
      "6. Fluent Python by Luciano Ramalho\n",
      "7. Python in a Nutshell by Alex Martelli\n",
      "8. Python Pocket Reference by Mark Lutz\n",
      "9. Python for Kids by Jason R. Briggs\n",
      "10. Python Essential Reference by David Beazley\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "much better response by the 'davinci-003' model..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and see what happens if we're able to train a weaker model.\n",
    "So we're going to use the Babbage model as our baseline of what we're trying to improve upon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning and Price Estimation\n",
    "\n",
    "We can use the **tiktoken** library to estimate costs, by counting tokens the same way OpenAI does. \n",
    "\n",
    "tiktoken support 3 different encodings for OpenAI models:   \n",
    "- *gpt2* for most gpt-3 models\n",
    "- *p50k_base* for code methods, and Davinci models, like **text-davinci-003**\n",
    "- *cl100k_base* for **text-embedding-ada-002**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string, encoding_name):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4429"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only first 500 rows for saving costs purposes\n",
    "dataset_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"example_trainin_data.json\",\"w\") as f:\n",
    "    for entry in qa_openai_format[:dataset_size]:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': \"This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\\n\\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\\n\\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\\n\\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\\n\\nHas anyone got any experiences of something similar to this they would care to share?\\n\", 'completion': \"I started writing up a summary of my experience with my own code generator, then went back and re-read your question and found you had already touched upon the same issues yourself, focus on the execution results instead of the code layout/look.\\n\\nProblem is, this is hard to test, the generated code might not be suited to actually run in the environment of the unit test system, and how do you encode the expected results?\\n\\nI've found that you need to break down the code generator into smaller pieces and unit test those. Unit testing a full code generator is more like integration testing than unit testing if you ask me.\\n\"}]\n"
     ]
    }
   ],
   "source": [
    "print(qa_openai_format[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = 0\n",
    "for prompt_completion in qa_openai_format:\n",
    "    for prompt, completion in prompt_completion.items():\n",
    "        token_counter += num_tokens_from_string(prompt,'gpt2')\n",
    "        token_counter += num_tokens_from_string(completion,'gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2719388"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2719388 tokens\n",
      "Fine tuning using babbage costs $0.0006 per 1000 tokens\n",
      "Estimated price: $6.526531199999999\n"
     ]
    }
   ],
   "source": [
    "# for babbage --> $0.0006 per 1000 tokens (training) * 4 epochs \n",
    "print(f\"There are {token_counter} tokens\")\n",
    "print(f\"Fine tuning using babbage costs $0.0006 per 1000 tokens\")\n",
    "print(f\"Estimated price: ${(4*token_counter / 1000) * 0.0006}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197362"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter = 0\n",
    "for prompt_completion in qa_openai_format[:500]:\n",
    "    for prompt, completion in prompt_completion.items():\n",
    "        token_counter += num_tokens_from_string(prompt,'gpt2')\n",
    "        token_counter += num_tokens_from_string(completion,'gpt2')\n",
    "token_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 197362 tokens\n",
      "Fine tuning using babbage costs $0.0006 per 1000 tokens\n",
      "Estimated price: $0.47366879999999995\n"
     ]
    }
   ],
   "source": [
    "# for babbage --> $0.0006 per 1000 tokens (training) * 4 epochs \n",
    "print(f\"There are {token_counter} tokens\")\n",
    "print(f\"Fine tuning using babbage costs $0.0006 per 1000 tokens\")\n",
    "print(f\"Estimated price: ${(4*token_counter / 1000) * 0.0006}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to conduct fine tuning.\n",
    "\n",
    "Openai documentation actually recommends using the command line tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line for Fine-Tuning\n",
    "\n",
    "Note, you can find the full official guide here:\n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning\n",
    "\n",
    "OpenAI recommends using the terminal/command line via their OpenAI tool, which you have by simply running:\n",
    "\n",
    "    pip install --upgrade openai\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    openai api fine_tunes.create -t training_data.json -m babbage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use:\n",
    "\n",
    "*openai api fine_tunes.list* to get a list of your fine tuning jobs, \n",
    "\n",
    "*openai api fine_tunes.get -i <YOUR_FINE_TUNE_JOB_ID>* to get the debug log of your fine tuning process\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cancel the fine-tuning job, run:\n",
    "\n",
    "    openai api fine_tunes.cancel -i (your_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fine tuned model from terminal\n",
    "fine_tuned_model = \"babbage:ft-sff-2023-03-23-19-48-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model\n",
    "response = openai.Completion.create(\n",
    "    model = 'text-babbage-001',\n",
    "    prompt = \"What are good Python books?\",\n",
    "    max_tokens = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Some good Python books that may be of interest include \"Python for Data Science & analytics\" or \"Python for Scientific Computing\".\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuned model\n",
    "response = openai.Completion.create(\n",
    "    model = fine_tuned_model,\n",
    "    prompt = \"What are good Python books?\",\n",
    "    max_tokens = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer is: it depends. For one, you should consider which language you are learning. Thus, the experiences of those who have learnt one language might be worth considering (hint hint...some of the excellent books listed here were written by an English dude). For the other hand, you might want to take a look at the Python general reading list.\n",
      "To begin with, I suggest Gitplug for a general overview of what's going on with the Python standard library. It's also a good idea to look at other books you might be planning on learning about python.  It's impossible to withall any learning curve with python\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In my opinion the top three (in rough order of best to worst) are:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What is Python?\n",
      "\n",
      "\t by Henrique Giegwn\n",
      "\n",
      "\t \t \t The book is short so you can read it in one sitting, and it's easy to follow.\n",
      "\n",
      "\t \t \t It's well written, but what I like best is the speaker restriction. If you are good at explaining things to other people, you'll know this book will be great for that.\n",
      "\n",
      "\n",
      "Real World Python\n",
      "\n",
      "\t \t \t Probably the best guide to use as a reference, this is brief enough to\n"
     ]
    }
   ],
   "source": [
    "# Another fine tuned model\n",
    "fine_tuned_model2 = \"babbage:ft-sff-2023-03-23-19-21-31\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model = fine_tuned_model2,\n",
    "    prompt = \"What are good Python books?\",\n",
    "    max_tokens = 128\n",
    ")\n",
    "print(response['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_openAIproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
